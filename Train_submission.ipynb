{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run models and create submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from custom_helpers import *\n",
    "from implementations import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II) Required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(y_train, x_train, flag_method, max_iter=1000, gamma=0.001, lambda_=0): \n",
    "    \"\"\"Train a model on a given subset of the data. Choose method by setting flag_method\"\"\"\n",
    "\n",
    "    initial_w = np.ones(x_train.shape[1])\n",
    "\n",
    "    if flag_method == 0:\n",
    "        # Use linear regression (full gradient descent)\n",
    "        weight, loss_tr = least_squares_GD(y_train, x_train, initial_w, max_iters, gamma)\n",
    "            \n",
    "    if flag_method == 1:\n",
    "        # Use linear regression (stochastic gradient descent)\n",
    "        weight, loss_tr = least_squares_SGD(y_train, x_train, initial_w, max_iters, gamma)\n",
    "        \n",
    "    if flag_method == 2:\n",
    "        # Use least squares method\n",
    "        weight, loss_tr = least_squares(y_train, x_train)\n",
    "            \n",
    "    if flag_method == 3:\n",
    "        # Use ridge regression\n",
    "        weight, loss_tr = ridge_regression(y_train, x_train, lambda_)\n",
    "           \n",
    "    if flag_method == 4:\n",
    "        # Use logistic regression\n",
    "        weight, loss_tr = logistic_regression(y_train, x_train, initial_w, max_iters, gamma)\n",
    "            \n",
    "    if flag_method == 5:\n",
    "        # Use regularized logistic regression\n",
    "        weight, loss_tr = reg_logistic_regression(y_train, x_train, initial_w, max_iters, gamma, lambda_)\n",
    "        \n",
    "    return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "print(\"Loading Data, please wait\")\n",
    "y_test, x_test_raw, ids_test = load_csv_data('data/test.csv')\n",
    "y_train, x_train_raw, ids_train = load_csv_data('data/train.csv')\n",
    "print(\"Data loaded, continue!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV) Train Model on the training set and make predictions on the testset\n",
    "Chose from the following methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Methods mapping\n",
    "0    Linear regression (full gradient descent)\n",
    "1    Linear regression (stochastic gradient descent)\n",
    "2    Least squares method\n",
    "3    Ridge regression\n",
    "4    Logistic regression (stochastic gradient descent)\n",
    "5    Regularized logistic regression (stochastic gradient descent)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train one model only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose feature treatment methods\n",
    "flag_add_offset = True\n",
    "flag_standardize = True\n",
    "flag_remove_outliers = True\n",
    "degree = 2\n",
    "\n",
    "# Choose training model to apply (see mapping above)\n",
    "flag_method = 2\n",
    "\n",
    "# Set training parameters\n",
    "max_iters = 20000\n",
    "gamma = 0.001\n",
    "lambda_ = 0.0\n",
    "\n",
    "# Prepare data\n",
    "print(\"Preparing data...\")\n",
    "x_train, x_test = prepare_data(x_train_raw, x_test_raw, flag_add_offset, flag_standardize, flag_remove_outliers, degree)\n",
    "\n",
    "# Train model\n",
    "print(\"Training starts...\")\n",
    "weight = train_model(y_train, x_train, flag_method, max_iters, gamma, lambda_)\n",
    "print(\"Training done!\")\n",
    "\n",
    "# Make predictions\n",
    "pred_y = predict_labels(weight, x_test)\n",
    "ids_pred_y = ids_test\n",
    "print(\"Predictions ready. You can now write them to a file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose filename:\n",
    "filename = \"SubmissionX.csv\"\n",
    "\n",
    "print(\"Creating submission file.\")\n",
    "create_csv_submission(ids_pred_y, pred_y, filename)\n",
    "print(\"Created submission file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a seperate model for each of the jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose feature treatment methods\n",
    "flag_add_offset = True\n",
    "flag_standardize = True\n",
    "flag_remove_outliers = True\n",
    "degree = 2\n",
    "\n",
    "# Choose training model to apply (see mapping above)\n",
    "flag_method = 2\n",
    "\n",
    "# Set training parameters\n",
    "max_iters = 2000\n",
    "gamma = 0.01\n",
    "lambda_ = 0.0\n",
    "\n",
    "# In the dateset, we found that the Column[22] PRI_jet_num dataset is categorical with Four categories defined.column_jet_nb = 22\n",
    "pred_y = []\n",
    "ids_pred_y = []\n",
    "column_categorical=22\n",
    "# In the paper where describes the differente features of the data, explains that different columns are invalid values\n",
    "# depending on the value of the categorical feature, so we can delete those values for the 4 different trainings\n",
    "#The undefined features, with first vector for the categorical value of 0, and so on.\n",
    "undefined_features = [[4, 5, 6, 12, 22, 23, 24, 25, 26, 27, 28, 29], [4, 5, 6, 12, 22, 26, 27, 28], [22], [22]]\n",
    "\n",
    "#We will have a for loop with 4 values for the 4 categorical training\n",
    "for nb_jets in range(0, 4):\n",
    "    print(\"Cleaning and preparing data for jet number %d\" %nb_jets)\n",
    "    # We will separate select data according to the value of the categorical values for each loop in our cicle\n",
    "    jet_index_test = x_test_raw[:, column_categorical] == nb_jets\n",
    "    x_test_jet = x_test_raw[jet_index_test]\n",
    "    y_test_jet = y_test[jet_index_test]\n",
    "    id_test_jet = ids_test[jet_index_test]\n",
    "    jet_index_train = x_train_raw[:, column_categorical] == nb_jets\n",
    "    x_train_jet = x_train_raw[jet_index_train]\n",
    "    y_train_jet = y_train[jet_index_train]\n",
    "    id_train_jet = ids_train[jet_index_train]\n",
    "    \n",
    "    #remove undefined features\n",
    "    x_test_jet = np.delete(x_test_jet, undefined_features[nb_jets], axis=1)\n",
    "    x_train_jet = np.delete(x_train_jet, undefined_features[nb_jets], axis=1)\n",
    "       \n",
    "    # Prepare data\n",
    "    x_train_jet, x_test_jet = prepare_data(x_train_jet, x_test_jet, flag_add_offset, flag_standardize, flag_remove_outliers, degree)\n",
    "\n",
    "    print(\"Training model for jet number %d...\" %nb_jets)\n",
    "    # train the chosen model\n",
    "    weight = train_model(y_train_jet, x_train_jet, flag_method, max_iters, gamma, lambda_)\n",
    "    \n",
    "    print(\"making predictions for jet number %d...\" %nb_jets)\n",
    "    # Now we get the prediction for y\n",
    "    pred_y_jet = predict_labels(weight, x_test_jet)\n",
    "    pred_y.extend(pred_y_jet)\n",
    "    ids_pred_y.extend(id_test_jet) \n",
    "\n",
    "print(\"Finished training all four models. Predictions are ready to be written to file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose filename:\n",
    "filename = \"SubmissionX_categorical.csv\"\n",
    "\n",
    "print(\"Creating submission file.\")\n",
    "create_csv_submission(ids_pred_y, pred_y, filename)\n",
    "print(\"Created submission file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
